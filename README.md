# Лабораторная работа №2

## Трекинг объекта на видео на основе ключевых точек

## 1. Цель работы

Целью данной лабораторной работы является реализация простейшего алгоритма трекинга объекта на видео на основе ключевых точек с использованием классических методов компьютерного зрения.


## 2. Теоретическая база

### 2.1. Ключевые точки

Ключевые точки представляют собой характерные локальные области изображения, устойчивые к небольшим геометрическим и фотометрическим искажениям. В данной работе ключевые точки используются как опорные элементы, по движению которых оценивается положение объекта на видео.

Для детекции ключевых точек применяется алгоритм **FAST (Features from Accelerated Segment Test)**. В отличие от методов, основанных на анализе матрицы градиентов (Harris, Shi–Tomasi), FAST использует критерий интенсивностных переходов в окрестности пикселя, что позволяет рассматривать его как альтернативный подход к выделению углов изображения.

### 2.2. Границы изображения

Для повышения устойчивости детекции ключевых точек используется алгоритм **Canny**, предназначенный для выделения границ изображения. В данной работе результат Canny применяется не как самостоятельный метод детекции объекта, а в качестве **маски**, ограничивающей области поиска ключевых точек.

Таким образом, ключевые точки детектируются преимущественно на границах объекта, что снижает количество ложных срабатываний на однородных или тёмных областях изображения.

### 2.3. Оптический поток Лукаса–Канаде

Для отслеживания движения ключевых точек между последовательными кадрами используется метод **оптического потока Лукаса–Канаде (Lucas–Kanade Optical Flow)** в разреженной постановке.

Метод основывается на следующих предположениях:

* яркость точки сохраняется между кадрами;
* смещение точки мало;
* движение локально однородно.

Алгоритм вычисляет смещение каждой ключевой точки между соседними кадрами, формируя траектории движения.

### 2.4. Оценка положения объекта

Положение объекта на каждом кадре определяется не напрямую, а косвенно — по пространственному распределению отслеживаемых ключевых точек. Для этого строится ограничивающая рамка (bounding box), вычисляемая по робастной статистике (процентилям координат точек), что позволяет снизить влияние выбросов.

## 3. Описание разработанной системы

### 3.1. Общий алгоритм работы

Алгоритм работы программы состоит из следующих этапов:

1. Загрузка входного видеофайла.
2. Чтение первого кадра видео.
3. Выделение границ изображения методом Canny.
4. Детекция ключевых точек методом FAST с использованием маски границ.
5. Инициализация трекинга ключевых точек.
6. Последовательная обработка кадров видео:

   * вычисление оптического потока Лукаса–Канаде;
   * отбрасывание потерянных ключевых точек;
   * визуализация траекторий движения;
   * вычисление ограничивающей рамки объекта.
7. Отображение и сохранение результирующего видео.

### 3.2. Архитектура решения

Программа реализована на языке **Python** с использованием библиотеки **OpenCV** и имеет линейную архитектуру, включающую следующие логические компоненты:

* модуль загрузки и чтения видео;
* модуль детекции границ;
* модуль детекции ключевых точек;
* модуль межкадрового трекинга;
* модуль визуализации и сохранения результата.

В работе не используются методы машинного обучения или нейронные сети.

### 3.3. Особенности реализации

* Ключевые точки детектируются только на первом кадре видео.
* Для повышения устойчивости детекции используется маска границ.
* Траектории ключевых точек накапливаются во времени и визуализируются в виде линий.
* Ограничивающая рамка строится на основе компактного кластера движущихся точек.
* Алгоритм не использует априорную модель объекта и не выполняет его сегментацию.

## 3.4. Основные параметры алгоритма

Реализованный алгоритм содержит ряд параметров, позволяющих адаптировать его работу под различные условия съёмки и качество входного видео.

* **ROI (область интереса)**
  Ограничивает область детекции ключевых точек на первом кадре. Позволяет снизить влияние фона и глобального движения камеры.

* **Параметры Canny (`CANNY_LOW`, `CANNY_HIGH`)**
  Определяют чувствительность детекции границ. Понижение порогов увеличивает число границ и ключевых точек, повышение — делает детекцию более устойчивой.

* **Параметры FAST (`FAST_THRESHOLD`)**
  Влияют на количество обнаруживаемых ключевых точек. Меньшие значения повышают чувствительность, большие — устойчивость детекции.

* **Ограничение числа точек (`MAX_POINTS`, `MIN_POINTS`)**
  Контролирует вычислительную сложность и минимальное количество точек, необходимое для трекинга.

* **Параметры оптического потока Лукаса–Канаде**
  Размер окна и число уровней пирамиды определяют устойчивость и точность межкадрового трекинга.

* **Параметры вычисления bounding box**
  Использование процентилей снижает влияние выбросов и стабилизирует размеры рамки.

## 4. Результаты работы и тестирования системы

Алгоритм был протестирован на нескольких видеопоследовательностях.

### 4.1. Тестовое видео: **mona-lisa**

**Описание видео:**
*Первый кадр - объект крупным планом. Объект остается на месте, оператор двигается вокруг объекта. Объект выделяется четкой формой, темными цветами по краям. Освещение равномерное*

**Результаты:**

![](paint_1.gif)

## **Наблюдения:**

* Видно, что бокс реагирует на изменение перспективы
* В качестве ключевых точек подцепилась сама мона лиза, а не прямоугольник (предположительно потому, что у нее больше локальных признаков) 
* Метод оптического потока Лукаса–Канаде не очень хорошо справился с поворотом изображения, рамка сузилась (возможно, это движение считается локально неоднородным? Либо это может быть связано с тем, что точки, по сути, остаются на месте (рамка как раз съезжает в сторону точек, которые дальше от оси вращения))


### 4.2. Тестовое видео: **mona-lisa-blur**

**Описание видео:**
*Присутствует небольшой блюр. Первый кадр - объект крупным планом. Объект остается на месте, оператор двигается вокруг объекта. Объект выделяется четкой формой, темными цветами по краям. Освещение равномерное*

**Результаты:**

![](paint_2.gif)

## **Наблюдения:**

* Наблюдение аналогично предыдущему, но эффект "сжатия" бокса при повороте меньше


### 4.3. Тестовое видео: **mona-lisa-extra-blur**

**Описание видео:**
*Еще больше блюра. Первый кадр - объект крупным планом. Объект остается на месте, оператор двигается вокруг объекта. Объект выделяется четкой формой, темными цветами по краям. Освещение равномерное*

**Результаты:**

![](paint_3.gif)

## **Наблюдения:**

* ключевые точки упали в основном на лицо и руки
* изменение перспективы не вызывает проблем с трекингом


### 4.4. Собственное видео

**Описание видео:**
*Освещение равномерное, с глубокими тенями. Объект отличается от фона цветом, контраст и текстура плохо различимы. Вокруг объекта - контрастные предметы с четкими границами. Резкое движение и потеря объекта из области видимости в конце видео*

**Результаты:**

![](fish.gif)

## **Наблюдения:**

* Сам объект содержит меньше ключевых точек, чем все вокруг. Пришлось задать ROI и понизить порог детектора FAST

* Резкое движение схватилось


## 5. Выводы по работе

В ходе выполнения лабораторной работы был реализован простой алгоритм трекинга объекта на основе ключевых точек и оптического потока.

В результате работы было установлено, что:

* алгоритмы, основанные на ключевых точках и разреженном оптическом потоке, позволяют отслеживать положение объекта без использования обучаемых моделей;
* использование маски границ повышает устойчивость детекции ключевых точек;
* при движении камеры оптический поток отражает глобальное движение сцены, что является ограничением простых методов трекинга;
* ограничивающая рамка объекта формируется по компактному кластеру ключевых точек с наиболее согласованным движением.

Полученные результаты соответствуют поставленной цели лабораторной работы.

## 6. Использованные источники

1. Lucas, B. D., Kanade, T. *An Iterative Image Registration Technique with an Application to Stereo Vision*. IJCAI, 1981.
2. Rosten, E., Drummond, T. *Machine Learning for High-Speed Corner Detection*. ECCV, 2006.
3. Canny, J. *A Computational Approach to Edge Detection*. IEEE TPAMI, 1986.
4. OpenCV Documentation — [https://docs.opencv.org](https://docs.opencv.org)




